{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae7d5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3466ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88f130e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data: pd.DataFrame) -> dict[str, float]:\n",
    "    \"\"\"Orchestrates the different steps for the model building phase and returns a dictionary with the model performances.\"\"\"\n",
    "    \n",
    "    # Splitting data into features and target variable\n",
    "    X_train = data.drop([\"Id\", \"SalePrice\"], axis=1)\n",
    "    y_train = data[\"SalePrice\"]\n",
    "    \n",
    "    # Splitting data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Defining continuous and categorical features\n",
    "    continuous_features = [\"LotArea\", \"GrLivArea\"]\n",
    "    categorical_features = [\"MSZoning\", \"Neighborhood\"] \n",
    "    \n",
    "    # Scaling continuous features and encoding categorical features\n",
    "    scaler = StandardScaler()\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    scaler.fit(X_train[continuous_features])\n",
    "    X_train[continuous_features] = scaler.transform(X_train[continuous_features])\n",
    "    encoder.fit(X_train[categorical_features])\n",
    "    X_train_processed = encoder.transform(X_train[categorical_features])\n",
    "    \n",
    "    # Fitting the model on the preprocessed training data\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.hstack((X_train[continuous_features], X_train_processed.toarray())), y_train)\n",
    "    \n",
    "    # Preprocessing the test data and generating predictions\n",
    "    X_test[continuous_features] = scaler.transform(X_test[continuous_features])\n",
    "    X_test_processed = encoder.transform(X_test[categorical_features])\n",
    "    y_pred = model.predict(np.hstack((X_test[continuous_features], X_test_processed.toarray())))\n",
    "    \n",
    "    # Computing model performances and returning them in a dictionary\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmsle = compute_rmsle(np.log(y_test), np.log(y_pred))\n",
    "    return {\"rmse\": rmse, \"rmsle\": rmsle}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd0a3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(input_data: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Orchestrates the different steps of the inference phase and returns the model predictions.\"\"\"\n",
    "    \n",
    "    # Loading the trained model and data preparation objects\n",
    "    model = joblib.load('../models/model.joblib')\n",
    "    encoder = joblib.load('../models/encoder.joblib')\n",
    "    scaler = joblib.load('../models/scaler.joblib')\n",
    "    \n",
    "    # Preprocessing the input data and generating predictions\n",
    "    continuous_features = [\"LotArea\", \"GrLivArea\"]\n",
    "    categorical_features = [\"MSZoning\", \"Neighborhood\"] \n",
    "    input_data[continuous_features] = scaler.transform(input_data[continuous_features])\n",
    "    input_data_processed = encoder.transform(input_data[categorical_features])\n",
    "    predictions = model.predict(np.hstack((input_data[continuous_features], input_data_processed.toarray())))\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a33f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47e26fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 42645.40610193754, 'rmsle': 0.02}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(pd.read_csv('/Users/admin-20218/Downloads/house-prices-advanced-regression-techniques/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8801268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88264.41248655, 150444.44970655, 195167.82402368, ...,\n",
       "       154777.70406753, 130722.18402166, 206036.98027394])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_predictions(pd.read_csv('/Users/admin-20218/Downloads/house-prices-advanced-regression-techniques/test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e9e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
